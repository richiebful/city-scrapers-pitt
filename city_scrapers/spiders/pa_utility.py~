from city_scrapers_core.constants import NOT_CLASSIFIED
from city_scrapers_core.items import Meeting
from city_scrapers_core.spiders import CityScrapersSpider
import pdfquery
import logging
import datetime
import re



class PaUtilitySpider(CityScrapersSpider):
    name = "pa_utility"
    agency = "PA Utility Commission"
    timezone = "America/New_York"
    allowed_domains = ["www.puc.state.pa.us"]
    start_urls = ["http://www.puc.state.pa.us/about_puc/public_meeting_calendar.aspx"]
    month_names = [
        "January", "February", "March", "April", "May", "June", "July", "August", "September",
        "October", "November", "December"
    ]

    def parse(self, response):
        """
        `parse` should always `yield` Meeting items.

        Change the `_parse_id`, `_parse_name`, etc methods to fit your scraping
        needs.
        """
        now = datetime.datetime.now()
        this_year = now.year
        next_year = this_year + 1
        pdf = pdfquery.PDFQuery('/home/rfulop/Downloads/{0}_PM_Schedule.pdf'.format(next_year))
        pdf.load()

        selections = [pdf.pq('LTTextLineHorizontal:contains("{0}")'.format(m)) for m in self.month_names]
        logging.debug(selections[0])
        monthly_dates = [s.text() for s in selections]
        str_dates = []
        for d in monthly_dates:
            str_dates += re.split('(?<=\d) ', d)

        dt_dates = []
        for d in str_dates:
            try:
                dt_dates.append(datetime.datetime.strptime(d, '%B %d, %Y'))
            except:
                continue
        
        for dt in dt_dates:
            meeting = Meeting(
                title=self._parse_title(item),
                description=self._parse_description(item),
                classification=self._parse_classification(item),
                start=self._parse_start(item),
                end=self._parse_end(item),
                all_day=self._parse_all_day(item),
                time_notes=self._parse_time_notes(item),
                location=self._parse_location(item),
                links=self._parse_links(item),
                source=self._parse_source(response),
            )

            meeting["status"] = self._get_status(meeting)
            meeting["id"] = self._get_id(meeting)

            yield meeting
        """
    def _parse_title(self, item):
        """Parse or generate meeting title."""
        return ""

    def _parse_description(self, item):
        """Parse or generate meeting description."""
        return ""

    def _parse_classification(self, item):
        """Parse or generate classification from allowed options."""
        return NOT_CLASSIFIED

    def _parse_start(self, item):
        """Parse start datetime as a naive datetime object."""
        return None

    def _parse_end(self, item):
        """Parse end datetime as a naive datetime object. Added by pipeline if None"""
        return None

    def _parse_time_notes(self, item):
        """Parse any additional notes on the timing of the meeting"""
        return ""

    def _parse_all_day(self, item):
        """Parse or generate all-day status. Defaults to False."""
        return False

    def _parse_location(self, item):
        """Parse or generate location."""
        return {
            "address": "",
            "name": "",
        }

    def _parse_links(self, item):
        """Parse or generate links."""
        return [{"href": "", "title": ""}]

    def _parse_source(self, response):
        """Parse or generate source."""
        return response.url
